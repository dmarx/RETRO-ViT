# video edit model + klmc2 + cold-diffusion = text2video

use klmc2 to generate a background (but in-domain) "noise" to pass to a video *editing* model, then repeatedly run editing passes to "decorrupt" the video, a la cold diffusion
