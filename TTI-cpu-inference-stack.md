# TTI cpu inference stack

![](https://img.shields.io/badge/tag-accessibility-lightgrey)  
![](https://img.shields.io/badge/tag-opensource-84f8cf)  
![](https://img.shields.io/badge/tag-tooling-lightgrey)  
![](https://img.shields.io/badge/tag-wip-lightgrey)  
![](https://img.shields.io/badge/tag-stability-lightgrey)


* port models to ONNX and compile
* quantize weights, low precision
* zero off-loading
