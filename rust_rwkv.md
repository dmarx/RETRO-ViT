# mini RWKV port

ggml port of https://huggingface.co/spaces/BlinkDL/ChatRWKV-gradio

also doesn't *have* to be ggml, just need to try some model compression techniques and see what happens. quantization might work better or worse for RNNs.

probably a lot of lit on compressing RNNs, maybe look into mobilenet type stuff.
