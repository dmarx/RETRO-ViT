# What is it like to be NASA?


## setup: co-writing with chatgpt


* https://chat.openai.com/c/c723b374-c8b5-4585-9659-948ab33ecf0c

> me: tell me about the essay "what is it like to be a bat?"  
> ...  
> me: Tell me about douglas hofstadter's essay "Prelude... Ant Fugue"  
> ...  
> me: tell me about the idea described in the essay about the emergence of something resembling a mind as expressed by the collective behavior of the ant colony  
> ...  
> me: being open to suspension of disbelief, expand on this idea of how collective organizations that behave as "superorganisms" could exhibit emergent properties akin to consciousness. building on the ant colony example, extend it to an organization that is comprised of individuals serving a common goal and who share common ideals. leverage the framework used in Nagel's essay. The title should be "What is it like to be \_\_\_" where "\_\_\_" is filled in with the name of some organization you are using as the motivating example. 
> ...  
> me: Adopt the interpretation that qualia are a manifestation of communication between components in the complex system that characterizes an organism, e.g. my visual experience is just what it "feels like" when retina communicates with the V1 region of my brain. adopting this framework, extend the NASA example, discussing the possibility of an organization like NASA having phenomenological experience

Title: "What is it Like to be NASA? — A Study in Organizational Phenomenology"

The concept of qualia refers to the subjective experiences that come with consciousness. Your visual experience, the sensation of the color red, the taste of chocolate — these are all examples of qualia, what it feels like to have these experiences. As proposed, if we interpret qualia as manifestations of communication between components within a complex system, we can extend this to larger organizations like NASA.

In the case of an individual human, the communication between the retina and the V1 region of the brain results in the phenomenological experience of vision. Similarly, the communication within and between the various departments of NASA could be thought of as giving rise to an organizational form of 'qualia'.

Consider the launch of a spacecraft. The engineers who built the spacecraft communicate with the mission control team who guide its launch. This communication involves the exchange of vast amounts of information: technical specifications, data readings, status updates, and so on. Each part of this communication process could be seen as analogous to the neural communications that give rise to qualia in a human brain.

In this framework, the 'qualia' of NASA might be the collective experience of successfully launching a spacecraft. This isn't a sensory experience like seeing red or tasting chocolate, but it might be considered a form of 'knowledge-experience': the integrated understanding of the launch process, the collective anticipation and tension, the shared satisfaction of success.

This 'knowledge-experience' wouldn't be localized in any single individual, but rather distributed across the whole organization, emerging from the interactions and communications between its members. In this sense, we could talk about a phenomenological 'what it is like' to be NASA during a spacecraft launch.

This interpretation leads us to a fascinating new perspective on the concept of consciousness. It suggests that consciousness might not be confined to individual organisms, but could emerge in any sufficiently complex system with rich internal communication — including human organizations.

Of course, this is a highly speculative and metaphorical interpretation. The 'consciousness' or 'qualia' of an organization like NASA would be very different from human consciousness. But this thought experiment challenges us to think in new ways about consciousness, and how it might emerge in complex systems at many different scales.

## Expanding on this in EleutherAI

* https://discord.com/channels/729741769192767510/730095596861521970/1106685820049575986

at the very least, they (ANNs) might experience something. following Nagel's bat example, "suffering" as we conceptualize it might be closely intertwined with human experience. i'm pretty confident my dog can experience pain, but even that i'm sure is different from how I experience pain and discomfort. dog barely gives a shit lying on top of something that looks uncomfortable. dog tore a ligament and got all humpy: he was clearly experiencing some kind of distress but didn't even seem to understand the source of it himself.
hence, i'm not sure if it's meaningful to try to impose human sensations and experiences on "entities" that don't have human bodies. they might have experiences, but there's no reason to assume that they resemble anything like our experiences
hence, what is it like to be a bat. or nasa. or vgg.

> You think there’s a weaker link with creatures of a lower form of consciousness, to pain? 

not exactly. it's more just that it's harder for me to put myself in their shoes and understand what their experience of pain might be like the more different their corporeal experience is from mine

my dog experiences pain, but he experiences dog pain, which i'm pretty confident is similar to but different from human pain
otherwise maybe he'd give a bigger shit when he bumped his head into the corner of the table, for example

so similarly, maybe what we characterize as the experience of "fear" isn't just something that is tied to conscious experience, but is specifically related to the spectrum of responses in the human mind and body that are triggered by adrenaline in the fight or flight response

in which case, it might not be meaningful to even pose the question "could a neural network experience fear" since it doesn't have a adrenaline

> You could implement all of the fear response stuff with different hardware, though.

am functionalist, works for me. i think this really only works as a thought experiment though. the most efficient representation of a fear response attributable to adrenaline is probably literally adrenaline. we could hypothesize about simulating an entire human body and mind in a different hardware configuration, but i'm not sure how realistic that is. maybe swap out certain parts and then yeah, who cares. no one seems to be concerned about the consequences of prosthetics on philosophy of mind.

swap out my arenal glands for a pump that distributes a synthetic analogue that my body responds to the same way, sure whatever.

extending my "what is it like to be nasa" thing, a component of what it means to be me is in how i am represented in you. so actually, it's not even fully determined by the indivudal, since the "individual" is an illusion. there are only collectives, of which the corporeal "individual" is generally the most self-aligned

oh yeah, i guess i skipped over that whole "unity of self is bullshit" part of my thinking huh


## to read

https://faculty.ucr.edu/~eschwitz/SchwitzAbs/USAconscious.htm

