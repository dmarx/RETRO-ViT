# Whisper STT + timestamps

![](https://img.shields.io/badge/tag-colab-lightgrey)  
![](https://img.shields.io/badge/tag-publicgood-lightgrey)  
![](https://img.shields.io/badge/tag-wip-84f8cf)  
![](https://img.shields.io/badge/tag-prompting-lightgrey)  
![](https://img.shields.io/badge/tag-dataset-lightgrey)  
![](https://img.shields.io/badge/tag-experimental-lightgrey)  
![](https://img.shields.io/badge/tag-tooling-lightgrey)  
![](https://img.shields.io/badge/tag-meta-lightgrey)  
![](https://img.shields.io/badge/tag-stability-lightgrey)

https://github.com/dmarx/video-killed-the-radio-star

---

https://colab.research.google.com/github/openai/whisper/blob/master/notebooks/LibriSpeech.ipynb#scrollTo=T5Gs4qD52D46

use grad cam on output tokens to infer per-token timestamps

see also: https://github.com/dmarx/bench-warmers/blob/main/subtitles-to-storyboard.md
